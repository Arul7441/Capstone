{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbL0F9XPxHqQCfpa6NFaHH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arul7441/Capstone/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "VcCy8I0D7WUg",
        "outputId": "938daeb8-2cdd-46f4-91de-58a9a6ec5c43"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OperationalError",
          "evalue": "connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (::1), port 5432 failed: Cannot assign requested address\n\tIs the server running on that host and accepting TCP/IP connections?\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-da05be4cc60e>\u001b[0m in \u001b[0;36m<cell line: 585>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;31m# PostgreSQL connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m mydb = psycopg2.connect(\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"localhost\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"postgres\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/psycopg2/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (::1), port 5432 failed: Cannot assign requested address\n\tIs the server running on that host and accepting TCP/IP connections?\n"
          ]
        }
      ],
      "source": [
        "# Youtube Data harvesting and Warehousing using SQL,MONGODB and StreamLit\n",
        "from googleapiclient.discovery import build\n",
        "import pymongo\n",
        "import psycopg2\n",
        "import pandas as pd\n",
        "import json\n",
        "import streamlit as st\n",
        "\n",
        "\n",
        "# API Key Connection\n",
        "def Api_Key_Connection():\n",
        "    Api_Id =\"AIzaSyBJGs8rTeDlCL6cgvEZaraE6yHptWg5FtA\"\n",
        "\n",
        "    Api_service_name = \"youtube\"\n",
        "    Api_version = \"v3\"\n",
        "    youtube = build(Api_service_name,Api_version,developerKey = Api_Id)\n",
        "    return youtube\n",
        "\n",
        "youtube = Api_Key_Connection()\n",
        "\n",
        "#get channel information\n",
        "def get_channel_info(channel_id):\n",
        "\n",
        "    request = youtube.channels().list(\n",
        "                part = \"snippet,contentDetails,Statistics\",\n",
        "                id = channel_id)\n",
        "\n",
        "    response1=request.execute()\n",
        "\n",
        "    for i in range(0,len(response1[\"items\"])):\n",
        "        data = dict(\n",
        "                    Channel_Name = response1[\"items\"][i][\"snippet\"][\"title\"],\n",
        "                    Channel_Id = response1[\"items\"][i][\"id\"],\n",
        "                    Subscription_Count= response1[\"items\"][i][\"statistics\"][\"subscriberCount\"],\n",
        "                    Views = response1[\"items\"][i][\"statistics\"][\"viewCount\"],\n",
        "                    Total_Videos = response1[\"items\"][i][\"statistics\"][\"videoCount\"],\n",
        "                    Channel_Description = response1[\"items\"][i][\"snippet\"][\"description\"],\n",
        "                    Playlist_Id = response1[\"items\"][i][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"],\n",
        "                    )\n",
        "        return data\n",
        "\n",
        "# get Playlist ids\n",
        "def get_playlist_info(channel_id):\n",
        "    All_data = []\n",
        "    next_page_token = None\n",
        "    next_page = True\n",
        "    while next_page:\n",
        "\n",
        "        request = youtube.playlists().list(\n",
        "            part=\"snippet,contentDetails\",\n",
        "            channelId=channel_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "            )\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            data={'PlaylistId':item['id'],\n",
        "                  'Title':item['snippet']['title'],\n",
        "                  'ChannelId':item['snippet']['channelId'],\n",
        "                  'ChannelName':item['snippet']['channelTitle'],\n",
        "                   'PublishedAt':item['snippet']['publishedAt'],\n",
        "                   'VideoCount':item['contentDetails']['itemCount']}\n",
        "            All_data.append(data)\n",
        "        next_page_token = response.get('nextPageToken')\n",
        "        if next_page_token is None:\n",
        "            next_page=False\n",
        "    return All_data\n",
        "\n",
        "# GET Video Id\n",
        "def get_video_ids(channel_id):\n",
        " video_ids=[]\n",
        " response=youtube.channels().list(id = channel_id,\n",
        "                                       part =\"contentDetails\").execute()\n",
        " Playlist_Id=response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        " next_page_token = None\n",
        "\n",
        "\n",
        " while True:\n",
        "     response1=youtube.playlistItems().list(\n",
        "                                    part =\"snippet\",\n",
        "                                    playlistId=Playlist_Id,\n",
        "                                    maxResults=50,\n",
        "                                    pageToken=next_page_token).execute()\n",
        "     for i in range(len(response1[\"items\"])):\n",
        "       video_ids.append(response1[\"items\"][i][\"snippet\"][\"resourceId\"][\"videoId\"])\n",
        "     next_page_token=response1.get(\"nextPageToken\")\n",
        "\n",
        "     if next_page_token is None:\n",
        "        break\n",
        " return video_ids\n",
        "\n",
        "#Get Video Information\n",
        "def get_video_info(video_ids):\n",
        "    video_data = []\n",
        "\n",
        "    for video_id in video_ids:\n",
        "        request = youtube.videos().list(\n",
        "            part=\"snippet,ContentDetails,statistics\",\n",
        "            id=video_id\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            data = dict(\n",
        "               Channel_Name=item['snippet']['channelTitle'],\n",
        "               Channel_Id=item['snippet']['channelId'],\n",
        "               Video_ID=item['id'],\n",
        "               Title=item['snippet']['title'],\n",
        "               Tags=item['snippet'].get('tags',['na']),\n",
        "               Thumbnail=item['snippet']['thumbnails']['default']['url'],\n",
        "               Description=item['snippet'].get('description',['na']),\n",
        "               Published_Date=item['snippet']['publishedAt'],\n",
        "               Duration=item['contentDetails']['duration'],\n",
        "               Views=item['statistics'].get('viewCount',0),\n",
        "               Likes = item['statistics'].get('likeCount',0),\n",
        "               Comments=item['statistics'].get('commentCount',0),\n",
        "               Favorite_Count=item['statistics']['favoriteCount'],\n",
        "               Definition=item['contentDetails']['definition'],\n",
        "               Caption_status=item['contentDetails']['caption']\n",
        "            )\n",
        "            video_data.append(data)\n",
        "    return video_data\n",
        "\n",
        "\n",
        "# Get Comment Information\n",
        "def get_Comment_information(video_ids):\n",
        "    Comment_data = []\n",
        "    try:\n",
        "        for video_id in video_ids:\n",
        "            request = youtube.commentThreads().list(\n",
        "                part=\"snippet\",\n",
        "                videoId=video_id,\n",
        "                maxResults=50\n",
        "            )\n",
        "            response = request.execute()\n",
        "\n",
        "            for item in response[\"items\"]:\n",
        "                data = dict(\n",
        "                    Comment_id=item['snippet']['topLevelComment']['id'],\n",
        "                    Video_Id=item['snippet']['topLevelComment']['snippet']['videoId'],\n",
        "                    Comment_Text=item['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
        "                    Comment_Author=item['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
        "                    Comment_Published_date=item['snippet']['topLevelComment']['snippet']['publishedAt'],\n",
        "                    LikeCount=item['snippet']['topLevelComment']['snippet']['likeCount']\n",
        "                )\n",
        "                Comment_data.append(data)\n",
        "    except:\n",
        "         pass\n",
        "    return Comment_data\n",
        "\n",
        "\n",
        "#MongoDB Connection Establishment\n",
        "client = pymongo.MongoClient(\"mongodb+srv://ramanaathan1:rAMANAA5882@cluster0.mzvob39.mongodb.net/?retryWrites=true&w=majority\")\n",
        "db=client[\"Youtube_data\"]\n",
        "\n",
        "\n",
        "# Upload to MongoDB\n",
        "def channel_details(channel_id):\n",
        "    ch_details=get_channel_info(channel_id)\n",
        "    pl_details=get_playlist_info(channel_id)\n",
        "    vi_ids=get_video_ids(channel_id)\n",
        "    vi_details=get_video_info(vi_ids)\n",
        "    comm_details=get_Comment_information(vi_ids)\n",
        "\n",
        "    collec1=db[\"channel_details\"]\n",
        "    collec1.insert_one({\"channel_information\":ch_details,\"playlist_information\":pl_details,\"video_information\":vi_details,\"comment_information\":comm_details})\n",
        "\n",
        "    return \"Upload Completed Successfully\"\n",
        "\n",
        "#CHANNEL DETAILS\n",
        "#Pawan Lalwani         \"UC5fs7PookxGfDPTo-RU0ReQ\"\n",
        "#Mr Gk                 \"UC5cY198GU1MQMIPJgMkCJ_Q\"\n",
        "#Data Science in tamil \"UCTCMjShTpZg96cXloCO9q1w\"\n",
        "#ScientificThamizhans  \"UCfbWU8xoxvzDSTQsqLNnVog\"\n",
        "#Mr T pokemon          \"UCU3wULlj7uCYKjZ32lbtazQ\"\n",
        "#Guri Bolte            \"UC7XZytvp1zBEMvnHm5lmwOA\"\n",
        "#Shridhar V            \"UCKQeGTsgUcO8eFoeSD-39rw\"\n",
        "#TanyaKhanijow         \"UCGeGhS_akOxBWQcSmje6B-w\"\n",
        "#KingsleyMusicLessons  \"UCv0kbxb0quwSawbx6nQekdg\"\n",
        "#electrophoenixzara    \"UC2TcWTdvMIcuSbHIJMHjPRA\"\n",
        "\n",
        "\n",
        "# Table Creation of channel:\n",
        "\n",
        "def channels_table():\n",
        "   # PostgreSQL connection\n",
        "   mydb = psycopg2.connect(host=\"localhost\",\n",
        "                            user=\"postgres\",\n",
        "                            password=\"onssnm1972\",\n",
        "                            database=\"Youtube_data\",\n",
        "                            port=\"5432\")\n",
        "   cursor = mydb.cursor()\n",
        "\n",
        "   # Drop existing table\n",
        "   drop_query = '''DROP TABLE IF EXISTS CHANNELS'''\n",
        "   cursor.execute(drop_query)\n",
        "   mydb.commit()\n",
        "\n",
        "   # Create new table\n",
        "   create_query = '''CREATE TABLE IF NOT EXISTS CHANNELS (Channel_Name VARCHAR(100),\n",
        "                                                          Channel_Id VARCHAR(80) PRIMARY KEY,\n",
        "                                                          Subscription_Count BIGINT,\n",
        "                                                          Views  BIGINT,\n",
        "                                                          Total_Videos INT ,\n",
        "                                                          Channel_Description Text ,\n",
        "                                                          Playlist_Id varchar(50)\n",
        "                                                            )'''\n",
        "   cursor.execute(create_query)\n",
        "   mydb.commit()\n",
        "\n",
        "   # MongoDB connection\n",
        "   db = client[\"Youtube_data\"]\n",
        "   colle1 = db[\"channel_details\"]\n",
        "\n",
        "   # Retrieve data from MongoDB\n",
        "   cl_list=[]\n",
        "   db = client[\"Youtube_data\"]\n",
        "   colle1 = db[\"channel_details\"]\n",
        "   for cl_data in colle1.find({}, {\"_id\": 0, \"channel_information\": 1}):\n",
        "        cl_list.append(cl_data[\"channel_information\"])\n",
        "   df = pd.DataFrame(cl_list)\n",
        "\n",
        "   # Insert values into PostgreSQL table\n",
        "   for index, row in df.iterrows():\n",
        "      insert_query = '''insert into channels (Channel_Name,\n",
        "                                              Channel_Id,\n",
        "                                              Subscription_Count,\n",
        "                                              Views,\n",
        "                                              Total_Videos,\n",
        "                                              Channel_Description,\n",
        "                                              Playlist_Id\n",
        "                                                )\n",
        "                                                VALUES(%s,%s,%s,%s,%s,%s,%s)'''\n",
        "      values = (\n",
        "            row['Channel_Name'],\n",
        "            row['Channel_Id'],\n",
        "            row['Subscription_Count'],\n",
        "            row['Views'],\n",
        "            row['Total_Videos'],\n",
        "            row['Channel_Description'],\n",
        "            row['Playlist_Id']\n",
        "        )\n",
        "      try:\n",
        "       cursor.execute(insert_query, values)\n",
        "       mydb.commit()\n",
        "\n",
        "      except:\n",
        "         print(\"playlist values are inserted\")\n",
        "\n",
        "\n",
        "\n",
        "# create playlist table\n",
        "def playlists_table():\n",
        "\n",
        "    # PostgreSQL connection\n",
        "    mydb = psycopg2.connect(\n",
        "        host=\"localhost\",\n",
        "        user=\"postgres\",\n",
        "        password=\"onssnm1972\",\n",
        "        database=\"Youtube_data\",\n",
        "        port=\"5432\"\n",
        "    )\n",
        "    cursor = mydb.cursor()\n",
        "\n",
        "    # Drop existing table\n",
        "    drop_query = '''DROP TABLE IF EXISTS PLAYLISTS'''\n",
        "    cursor.execute(drop_query)\n",
        "    mydb.commit()\n",
        "\n",
        "    # Create new table\n",
        "    try:\n",
        "        create_query ='''CREATE TABLE IF NOT EXISTS PLAYLISTS (\n",
        "                        PlaylistId\t VARCHAR(100) PRIMARY KEY,\n",
        "                        Title VARCHAR(100),\n",
        "                        ChannelId VARCHAR(100),\n",
        "                        ChannelName VARCHAR(100),\n",
        "                        PublishedAt TIMESTAMP,\n",
        "                        VideoCount INT\n",
        "                    )'''\n",
        "        cursor.execute(create_query)\n",
        "        mydb.commit()\n",
        "\n",
        "    except:\n",
        "        print(\"playlist table already created\")\n",
        "\n",
        "\n",
        "    # MongoDB connection\n",
        "    db = client[\"Youtube_data\"]\n",
        "    colle1 = db[\"channel_details\"]\n",
        "\n",
        "    # Retrieve data from MongoDB\n",
        "    pl_list = []\n",
        "    for pl_data in colle1.find({}, {\"_id\": 0, \"playlist_information\": 1}):\n",
        "        for i in range(len(pl_data[\"playlist_information\"])):\n",
        "            pl_list.append(pl_data[\"playlist_information\"][i])\n",
        "    df1 = pd.DataFrame(pl_list)\n",
        "\n",
        "    # Insert values into PostgreSQL table\n",
        "    for index, row in df1.iterrows():\n",
        "        insert_query = '''insert into playlists (\n",
        "                            PlaylistId\t,\n",
        "                            Title,\n",
        "                            ChannelId,\n",
        "                            ChannelName,\n",
        "                            PublishedAt,\n",
        "                            VideoCount\n",
        "                        )\n",
        "                        VALUES(%s,%s,%s,%s,%s,%s)'''\n",
        "        values = (\n",
        "            row['PlaylistId'],\n",
        "            row['Title'],\n",
        "            row['ChannelId'],\n",
        "            row['ChannelName'],\n",
        "            row['PublishedAt'],\n",
        "            row['VideoCount']\n",
        "        )\n",
        "        try:\n",
        "            cursor.execute(insert_query, values)\n",
        "            mydb.commit()\n",
        "        except:\n",
        "            print(\"playlist table values are inserted\")\n",
        "\n",
        "\n",
        "# create videos table\n",
        "def videos_table():\n",
        "    # PostgreSQL connection\n",
        "    mydb = psycopg2.connect(host=\"localhost\",\n",
        "                user=\"postgres\",\n",
        "                password=\"onssnm1972\",\n",
        "                database= \"Youtube_data\",\n",
        "                port = \"5432\"\n",
        "                )\n",
        "    cursor = mydb.cursor()\n",
        "\n",
        "    drop_query = \"drop table if exists videos\"\n",
        "    cursor.execute(drop_query)\n",
        "    mydb.commit()\n",
        "\n",
        "    try:\n",
        "        create_query = '''create table if not exists videos(\n",
        "                        Channel_Name varchar(150),\n",
        "                        Channel_Id varchar(100),\n",
        "                        Video_ID varchar(50) primary key,\n",
        "                        Title varchar(150),\n",
        "                        Tags text,\n",
        "                        Thumbnail varchar(225),\n",
        "                        Description text,\n",
        "                        Published_Date timestamp,\n",
        "                        Duration interval,\n",
        "                        Views bigint,\n",
        "                        Likes bigint,\n",
        "                        Comments int,\n",
        "                        Favorite_Count int,\n",
        "                        Definition varchar(10),\n",
        "                        Caption_status varchar(50)\n",
        "                        )'''\n",
        "\n",
        "        cursor.execute(create_query)\n",
        "        mydb.commit()\n",
        "    except:\n",
        "        st.write(\"Videos Table already created\")\n",
        "\n",
        "    vi_list = []\n",
        "    db = client[\"Youtube_data\"]\n",
        "    colle1 = db[\"channel_details\"]\n",
        "    for vi_data in colle1.find({},{\"_id\":0,\"video_information\":1}):\n",
        "        for i in range(len(vi_data[\"video_information\"])):\n",
        "            vi_list.append(vi_data[\"video_information\"][i])\n",
        "    df2 = pd.DataFrame(vi_list)\n",
        "\n",
        "\n",
        "    for index, row in df2.iterrows():\n",
        "        insert_query = '''\n",
        "                    INSERT INTO videos (Channel_Name,\n",
        "                                        Channel_Id,\n",
        "                                        Video_ID,\n",
        "                                        Title,\n",
        "                                        Tags,\n",
        "                                        Thumbnail,\n",
        "                                        Description,\n",
        "                                        Published_Date,\n",
        "                                        Duration,\n",
        "                                        Views,\n",
        "                                        Likes,\n",
        "                                        Comments,\n",
        "                                        Favorite_Count,\n",
        "                                        Definition,\n",
        "                                        Caption_status\n",
        "                                      )\n",
        "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
        "\n",
        "                '''\n",
        "        values = (\n",
        "                    row['Channel_Name'],\n",
        "                    row['Channel_Id'],\n",
        "                    row['Video_ID'],\n",
        "                    row['Title'],\n",
        "                    row['Tags'],\n",
        "                    row['Thumbnail'],\n",
        "                    row['Description'],\n",
        "                    row['Published_Date'],\n",
        "                    row['Duration'],\n",
        "                    row['Views'],\n",
        "                    row['Likes'],\n",
        "                    row['Comments'],\n",
        "                    row['Favorite_Count'],\n",
        "                    row['Definition'],\n",
        "                    row['Caption_status'])\n",
        "\n",
        "        try:\n",
        "            cursor.execute(insert_query,values)\n",
        "            mydb.commit()\n",
        "        except:\n",
        "            st.write(\"videos values  inserted in the table\")\n",
        "\n",
        "\n",
        "# create comment table\n",
        "def comment_table():\n",
        "    # PostgreSQL connection\n",
        "    mydb = psycopg2.connect(\n",
        "        host=\"localhost\",\n",
        "        user=\"postgres\",\n",
        "        password=\"onssnm1972\",\n",
        "        database=\"Youtube_data\",\n",
        "        port=\"5432\"\n",
        "    )\n",
        "    cursor = mydb.cursor()\n",
        "\n",
        "    # Drop existing table\n",
        "    drop_query = '''DROP TABLE IF EXISTS COMMENTS'''\n",
        "    cursor.execute(drop_query)\n",
        "    mydb.commit()\n",
        "\n",
        "    # Create new table\n",
        "    create_query = '''CREATE TABLE IF NOT EXISTS COMMENTS (\n",
        "        Comment_id VARCHAR(100) PRIMARY KEY,\n",
        "        Video_Id VARCHAR(50),\n",
        "        Comment_Text TEXT,\n",
        "        Comment_Author VARCHAR(150),\n",
        "        Comment_Published_date TIMESTAMP,\n",
        "        LikeCount INT\n",
        "    )'''\n",
        "    cursor.execute(create_query)\n",
        "    mydb.commit()\n",
        "\n",
        "    # MongoDB connection\n",
        "    db = client[\"Youtube_data\"]\n",
        "    collec1 = db[\"channel_details\"]\n",
        "\n",
        "    # Retrieve data from MongoDB\n",
        "    com_list = []\n",
        "    for com_data in collec1.find({}, {\"_id\": 0, \"comment_information\": 1}):\n",
        "        for i in range(len(com_data[\"comment_information\"])):\n",
        "            com_list.append(com_data[\"comment_information\"][i])\n",
        "\n",
        "    # Create DataFrame from MongoDB data\n",
        "    df3 = pd.DataFrame(com_list)\n",
        "\n",
        "    # Insert values into PostgreSQL table\n",
        "    for index, row in df3.iterrows():\n",
        "        insert_query = '''\n",
        "            INSERT INTO comments (\n",
        "                             Comment_id,\n",
        "                             Video_Id,\n",
        "                             Comment_Text,\n",
        "                             Comment_Author,\n",
        "                             Comment_Published_date,\n",
        "                             LikeCount\n",
        "                           )\n",
        "                           VALUES (%s, %s, %s, %s, %s, %s)\n",
        "                       '''\n",
        "        values = (\n",
        "            row['Comment_id'],\n",
        "            row['Video_Id'],\n",
        "            row['Comment_Text'],\n",
        "            row['Comment_Author'],\n",
        "            row['Comment_Published_date'],\n",
        "            row['LikeCount']\n",
        "        )\n",
        "        try:\n",
        "            cursor.execute(insert_query, values)\n",
        "            mydb.commit()\n",
        "        except:\n",
        "            print(\"comment values are inserted\")\n",
        "\n",
        "\n",
        "\n",
        "def all_tables():\n",
        "    channels_table()\n",
        "    playlists_table()\n",
        "    videos_table()\n",
        "    comment_table()\n",
        "\n",
        "    return \"Tables created successfully\"\n",
        "\n",
        "def show_channels_table():\n",
        "  cl_list=[]\n",
        "  db = client[\"Youtube_data\"]\n",
        "  colle1 = db[\"channel_details\"]\n",
        "  for cl_data in colle1.find({}, {\"_id\": 0, \"channel_information\": 1}):\n",
        "      cl_list.append(cl_data[\"channel_information\"])\n",
        "  df = st.dataframe(cl_list)\n",
        "\n",
        "  return df\n",
        "\n",
        "def show_playlists_table():\n",
        "  pl_list = []\n",
        "  db = client[\"Youtube_data\"]\n",
        "  colle1 = db[\"channel_details\"]\n",
        "  for pl_data in colle1.find({}, {\"_id\": 0, \"playlist_information\": 1}):\n",
        "      for i in range(len(pl_data[\"playlist_information\"])):\n",
        "        pl_list.append(pl_data[\"playlist_information\"][i])\n",
        "  df1 = st.dataframe(pl_list)\n",
        "\n",
        "  return df1\n",
        "\n",
        "def show_videos_table():\n",
        "  vi_list = []\n",
        "  db = client[\"Youtube_data\"]\n",
        "  collec1 = db[\"channel_details\"]\n",
        "  for vi_data in collec1.find({}, {\"_id\": 0, \"video_information\": 1}):\n",
        "      for i in range(len(vi_data[\"video_information\"])):\n",
        "        vi_list.append(vi_data[\"video_information\"][i])\n",
        "  df2 = st.dataframe(vi_list)\n",
        "\n",
        "  return df2\n",
        "\n",
        "def show_comments_table():\n",
        "  com_list = []\n",
        "  db = client[\"Youtube_data\"]\n",
        "  collec1 = db[\"channel_details\"]\n",
        "  for com_data in collec1.find({}, {\"_id\": 0, \"comment_information\": 1}):\n",
        "      for i in range(len(com_data[\"comment_information\"])):\n",
        "         com_list.append(com_data[\"comment_information\"][i])\n",
        "  df3 = st.dataframe(com_list)\n",
        "\n",
        "  return df3\n",
        "\n",
        "\n",
        "# streamlit\n",
        "with st.sidebar:\n",
        "  st.sidebar.title(\"YOUTUBE DATA HARVESTING AND WAREHOUSING\")\n",
        "  st.sidebar.header(\"Project benefits\")\n",
        "  st.sidebar.caption(\"Explore the YouTube API: Learn how to access and fetch data from YouTube's extensive API...\")\n",
        "\n",
        "st.sidebar.subheader(\"Data Collection\")\n",
        "new_channel_id = st.sidebar.text_input(\"ENTER NEW CHANNEL ID\")\n",
        "if st.sidebar.button(\"COLLECT AND STORE DATA IN MONGODB\"):\n",
        "    ch_ids = []\n",
        "    db = client[\"Youtube_data\"]\n",
        "    collec1 = db[\"channel_details\"]\n",
        "    for ch_data in collec1.find({}, {\"_id\": 0, \"channel_information\": 1}):\n",
        "        ch_ids.append(ch_data[\"channel_information\"][\"Channel_Id\"])\n",
        "\n",
        "    if new_channel_id in ch_ids:\n",
        "        st.sidebar.warning(\"CHANNEL DETAILS OF THE GIVEN CHANNEL ID ALREADY EXISTS \")\n",
        "    else:\n",
        "        insert = channel_details(new_channel_id)\n",
        "        st.sidebar.success(insert)\n",
        "\n",
        "st.sidebar.subheader(\"Table Migration\")\n",
        "if st.sidebar.button(\"MIGRATE TO POSTGRESQL\"):\n",
        "    Table = all_tables()\n",
        "    st.sidebar.success(Table)\n",
        "\n",
        "# Show output as dataframes in streamlit\n",
        "show_table = st.radio(\"SELECT THE TABLE FOR VIEW\",(\"CHANNELS\",\"PLAYLISTS\",\"VIDEOS\",\"COMMENTS\"))\n",
        "\n",
        "if show_table ==\"CHANNELS\":\n",
        "   show_channels_table()\n",
        "\n",
        "elif show_table ==\"PLAYLISTS\":\n",
        "   show_playlists_table()\n",
        "\n",
        "elif show_table == \"VIDEOS\":\n",
        "   show_videos_table()\n",
        "\n",
        "elif show_table ==\"COMMENTS\":\n",
        "   show_comments_table()\n",
        "\n",
        "\n",
        "# PostgreSQL connection\n",
        "mydb = psycopg2.connect(\n",
        "        host=\"localhost\",\n",
        "        user=\"postgres\",\n",
        "        password=\"onssnm1972\",\n",
        "        database=\"Youtube_data\",\n",
        "        port=\"5432\"\n",
        "    )\n",
        "cursor = mydb.cursor()\n",
        "\n",
        "\n",
        "\n",
        "Question = st.selectbox(\"EXECUTE QUESTION\",    (\"1.What are the names of all the videos and their corresponding channels?\",\n",
        "                                                \"2.Which channels have the most number of videos, and how many videos do they have?\",\n",
        "                                                \"3.What are the top 10 most viewed videos and their respective channels?\",\n",
        "                                                \"4.How many comments were made on each video, and what are their corresponding video names?\",\n",
        "                                                \"5.Which videos have the highest number of likes, and what are their corresponding channel names?\",\n",
        "                                                \"6.What is the total number of likes and dislikes for each video, and what are their corresponding video names?\",\n",
        "                                                \"7.What is the total number of views for each channel, and what are their corresponding channel names?\",\n",
        "                                                \"8.What are the names of all the channels that have published videos in the year 2022?\",\n",
        "                                                \"9.What is the average duration of all videos in each channel, and what are their corresponding channel names?\",\n",
        "                                                \"10.Which videos have the highest number of comments, and what are their corresponding channel names?\" ))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if Question == '1.What are the names of all the videos and their corresponding channels?':\n",
        "   query1 ='''select channel_name as channelname ,title as Videotitle from videos '''\n",
        "   cursor.execute(query1)\n",
        "   mydb.commit()\n",
        "   t1=cursor.fetchall()\n",
        "   st.write(pd.DataFrame(t1,columns=[\"CHANNEL NAME\",\"VIDEO TITLE\"]))\n",
        "\n",
        "\n",
        "elif Question == '2.Which channels have the most number of videos, and how many videos do they have?':\n",
        "   query2 ='''select channel_name as channelname,total_videos as no_of_videos from channels\n",
        "           order by total_videos desc'''\n",
        "   cursor.execute(query2)\n",
        "   mydb.commit()\n",
        "   t2=cursor.fetchall()\n",
        "   st.write(pd.DataFrame(t2,columns=[\"CHANNEL NAME\",\"NO OF VIDEOS\"]))\n",
        "\n",
        "\n",
        "elif Question ==  '3.What are the top 10 most viewed videos and their respective channels?':\n",
        "    query3 = '''select Views as views , Channel_Name as ChannelName,Title as VideoTitle from videos\n",
        "                        where Views is not null order by Views desc limit 10;'''\n",
        "    cursor.execute(query3)\n",
        "    mydb.commit()\n",
        "    t3 = cursor.fetchall()\n",
        "    st.write(pd.DataFrame(t3, columns = [\"VIEWS\",\"CHANNEL NAME\",\"VIDEO TITLE\"]))\n",
        "\n",
        "elif Question == '4.How many comments were made on each video, and what are their corresponding video names?':\n",
        "    query4 = \"select Comments as Nocomments ,Title as VideoTitle from videos where Comments is not null;\"\n",
        "    cursor.execute(query4)\n",
        "    mydb.commit()\n",
        "    t4=cursor.fetchall()\n",
        "    st.write(pd.DataFrame(t4, columns=[\"NO COMMENTS\", \"VIDEO TITLE\"]))\n",
        "\n",
        "\n",
        "elif Question == '5.Which videos have the highest number of likes, and what are their corresponding channel names?':\n",
        "    query5 = '''select Title as VideoTitle, Channel_Name as ChannelName, Likes as LikesCount from videos\n",
        "                       where Likes is not null order by Likes desc;'''\n",
        "    cursor.execute(query5)\n",
        "    mydb.commit()\n",
        "    t5 = cursor.fetchall()\n",
        "    t5_df = pd.DataFrame(t5, columns=[\"VIDEO TITLE\", \"CHANNEL NAME\", \"LIKE COUNT\"])\n",
        "    t5_df['LIKE COUNT'] = t5_df['LIKE COUNT'].astype(bytes)\n",
        "    # Display the DataFrame in Streamlit\n",
        "    st.write(t5_df)\n",
        "\n",
        "\n",
        "elif Question == '6.What is the total number of likes and dislikes for each video, and what are their corresponding video names?':\n",
        "    query6 = '''select Likes as likeCount,Title as VideoTitle from videos;'''\n",
        "    cursor.execute(query6)\n",
        "    mydb.commit()\n",
        "    t6 = cursor.fetchall()\n",
        "    st.write(pd.DataFrame(t6, columns=[\"LIKE COUNT\",\"VIDEO TITLE\"]))\n",
        "\n",
        "\n",
        "elif Question == '7.What is the total number of views for each channel, and what are their corresponding channel names?':\n",
        "    query7 = \"select Channel_Name as ChannelName, Views as Channelviews from channels;\"\n",
        "    cursor.execute(query7)\n",
        "    mydb.commit()\n",
        "    t7=cursor.fetchall()\n",
        "    st.write(pd.DataFrame(t7, columns=[\"CHANNEL NAME\",\"TOTAL VIEWS\"]))\n",
        "\n",
        "\n",
        "elif Question == '8.What are the names of all the channels that have published videos in the year 2022?':\n",
        "    query8 = '''select Title as Video_Title, Published_Date as VideoRelease, Channel_Name as ChannelName from videos\n",
        "                where extract(year from Published_Date) = 2022;'''\n",
        "    cursor.execute(query8)\n",
        "    mydb.commit()\n",
        "    t8=cursor.fetchall()\n",
        "    st.write(pd.DataFrame(t8,columns=[\"NAME\", \"VIDEO PUBLISHED ON\", \"CHANNELNAME\"]))\n",
        "\n",
        "\n",
        "elif Question == '9.What is the average duration of all videos in each channel, and what are their corresponding channel names?':\n",
        "    query9 =  \"SELECT Channel_Name as ChannelName, AVG(Duration) AS average_duration FROM videos GROUP BY Channel_Name;\"\n",
        "    cursor.execute(query9)\n",
        "    mydb.commit()\n",
        "    t9=cursor.fetchall()\n",
        "    t9 = pd.DataFrame(t9, columns=['CHANNELTITLE', 'AVERAGEDURATION'])\n",
        "    T9=[]\n",
        "    for index, row in t9.iterrows():\n",
        "        channel_title = row['CHANNELTITLE']\n",
        "        average_duration = row['AVERAGEDURATION']\n",
        "        average_duration_str = str(average_duration)\n",
        "        T9.append({\"'CHANNELTITLE'\": channel_title ,  \"AVERAGEDURATION\": average_duration_str})\n",
        "    st.write(pd.DataFrame(T9))\n",
        "\n",
        "\n",
        "elif Question == '10.Which videos have the highest number of comments, and what are their corresponding channel names?':\n",
        "   query10 = '''select Title as VideoTitle, Channel_Name as ChannelName, Comments as Comments from videos\n",
        "                       where Comments is not null order by Comments desc;'''\n",
        "   cursor.execute(query10)\n",
        "   mydb.commit()\n",
        "   t10=cursor.fetchall()\n",
        "   st.write(pd.DataFrame(t10, columns=['VIDEO TITLE', 'CHANNEL NAME', 'NO OF COMMENTS']))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-api-python-client pymongo psycopg2-binary pandas streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fUAbaYNi97g0",
        "outputId": "2e406ae6-0f88-4650-9053-bd6928fb989b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.84.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.6.1)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.31.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<8,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (7.0.1)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.41)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.62.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<8,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.17.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.5.1)\n",
            "Installing collected packages: psycopg2-binary\n",
            "Successfully installed psycopg2-binary-2.9.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psycopg2"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n"
      ],
      "metadata": {
        "id": "4ZvAzl2s9VCC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mydb = sqlite3.connect('your_database_name.db')\n"
      ],
      "metadata": {
        "id": "_7mjGWep8z1m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl9NZNwo8NCm",
        "outputId": "7baff149-db2e-4b2f-aea5-32f654ebfad2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.31.0-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<8,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (7.0.1)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<8,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.17.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.41 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.31.0 validators-0.22.0 watchdog-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL3VAOWJ7z2Y",
        "outputId": "7c7ed416-78ce-4c72-ab4e-8040f7181380"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.5.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.4/305.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.5.0 pymongo-4.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install psycopg2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRP-CBpI77J9",
        "outputId": "8cbc3686-d543-4f95-9b8b-75b85f763da8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.10/dist-packages (2.9.9)\n"
          ]
        }
      ]
    }
  ]
}